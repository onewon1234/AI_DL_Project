# KLUE-BERT Pairwise 문장 순서 예측 모델 (수정된 버전)

# 1. 필요한 라이브러리 import
import pandas as pd
import numpy as np
import re
from tqdm.auto import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from scipy.stats import loguniform
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, f1_score, precision_score, recall_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)
import itertools
from itertools import permutations
from transformers import (
    AutoTokenizer,
    AutoModel,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback
)
import os
os.environ["WANDB_DISABLED"] = "true"

print("라이브러리 import 완료")

# 환경 확인
print(f"PyTorch 버전: {torch.__version__}")
print(f"CUDA 사용 가능: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA 디바이스: {torch.cuda.get_device_name(0)}")

# Google Drive 마운트
from google.colab import drive
drive.mount('/content/drive')

# 데이터 로드
train = pd.read_csv('/content/drive/MyDrive/data/daycon_sentence/train.csv')
test = pd.read_csv('/content/drive/MyDrive/data/daycon_sentence/test.csv')
submission = pd.read_csv('/content/drive/MyDrive/data/daycon_sentence/sample_submission.csv')

print("=== 데이터 로드 완료 ===")
print(f"Train 데이터: {len(train)} 샘플")
print(f"Test 데이터: {len(test)} 샘플")
print(f"Submission 형식: {submission.shape}")

# 데이터 기본 정보 확인
print("=== Train 데이터 정보 ===")
train.info()
print("\n=== Test 데이터 정보 ===")
test.info()
print("\n=== Submission 형식 ===")
submission.info()

# 텍스트 정제 함수
def clean_text(text):
    # 특수문자 제거
    text = re.sub(r'[^\w\s]', '', text)
    # 소문자 변환: 한글에는 무의미
    text = text.lower()
    # 불필요한 공백 제거
    text = ' '.join(text.split())
    return text

# 텍스트 정제 적용
for i in range(4):
    train[f'sentence_{i}'] = train[f'sentence_{i}'].apply(clean_text)
    test[f'sentence_{i}'] = test[f'sentence_{i}'].apply(clean_text)

print("텍스트 정제 완료")
print(f"정제 전후 비교:")
print(f"정제 전: {train['sentence_0'].iloc[0]}")
print(f"정제 후: {train['sentence_0'].iloc[0]}")

## ✅ Pairwise 전처리 함수
def preprocess_pairwise(df):
    """
    문장들을 pairwise 형태로 변환
    각 문장 쌍에 대해 올바른 순서인지 여부를 레이블링
    """
    data = []
    for _, row in df.iterrows():
        sentences = [row[f'sentence_{i}'] for i in range(4)]
        answer = [row[f'answer_{i}'] for i in range(4)]
        
        # 올바른 순서로 정렬된 문장들
        ordered = [sentences[i] for i in answer]
        
        # 올바른 순서의 쌍들 (연속된 3개 쌍)
        positive_pairs = [(ordered[i], ordered[i+1]) for i in range(3)]
        
        # 모든 가능한 쌍들 (6개)
        all_pairs = list(itertools.permutations(sentences, 2))
        
        # 각 쌍에 대해 레이블링
        for s1, s2 in all_pairs:
            label = 1 if (s1, s2) in positive_pairs else 0
            data.append({'sentence1': s1, 'sentence2': s2, 'label': label})
    
    return pd.DataFrame(data)

# Pairwise 데이터 생성
pairwise_df = preprocess_pairwise(train)

print("=== Pairwise 데이터 정보 ===")
pairwise_df.info()
print("\n=== 클래스 분포 ===")
print(pairwise_df['label'].value_counts())
print(f"\n클래스 비율: {pairwise_df['label'].value_counts(normalize=True)}")

# 클래스 불균형 확인
num_zeros = pairwise_df['label'].value_counts()[0]
num_ones = pairwise_df['label'].value_counts()[1]
print(f"\n클래스 0 (잘못된 순서): {num_zeros}개")
print(f"클래스 1 (올바른 순서): {num_ones}개")
print(f"불균형 비율: {num_zeros/num_ones:.2f}:1")

# 클래스 불균형 해결을 위한 가중치 계산
total = num_zeros + num_ones
weight_for_0 = total / (2 * num_zeros)
weight_for_1 = total / (2 * num_ones)

class_weights = torch.tensor([weight_for_0, weight_for_1], dtype=torch.float)
print("=== 클래스 가중치 ===")
print(f"클래스 0 가중치: {weight_for_0:.4f}")
print(f"클래스 1 가중치: {weight_for_1:.4f}")
print(f"가중치 비율: {weight_for_1/weight_for_0:.2f}:1")

# 2. 데이터셋 구성
MAX_TOKEN_LENGTH = 128

# 데이터셋 클래스 정의
class SentencePairDataset(Dataset):
    """
    문장 쌍을 받아 BERT 입력 형식으로 변환하는 PyTorch Dataset 클래스
    """
    def __init__(self, dataframe, tokenizer, max_length=MAX_TOKEN_LENGTH):
        self.data = dataframe
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        row = self.data.iloc[idx]
        encoding = self.tokenizer(
            row['sentence1'],
            row['sentence2'],
            padding='max_length',
            truncation=True,
            max_length=self.max_length,
            return_tensors='pt'
        )

        item = {
            'input_ids': encoding['input_ids'][0],
            'attention_mask': encoding['attention_mask'][0],
            'labels': torch.tensor(row['label'], dtype=torch.long)
        }

        if 'token_type_ids' in encoding:
            item['token_type_ids'] = encoding['token_type_ids'][0]

        return item

# 3. 모델 아키텍처 (KLUE-BERT)
class SentencePairModel(nn.Module):
    def __init__(self, model_name, num_labels=2, class_weights=None):
        super(SentencePairModel, self).__init__()
        self.bert = AutoModel.from_pretrained(model_name)
        self.dropout = nn.Dropout(0.1)
        self.classifier = nn.Linear(self.bert.config.hidden_size, num_labels)
        
        # 클래스 가중치 적용
        if class_weights is not None:
            self.loss_fn = nn.CrossEntropyLoss(weight=class_weights)
        else:
            self.loss_fn = nn.CrossEntropyLoss()

    def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):
        outputs = self.bert(
            input_ids=input_ids,
            attention_mask=attention_mask,
            token_type_ids=token_type_ids,
            output_hidden_states=True,
            return_dict=True
        )

        # 마지막 4개 hidden layer 평균 (성능 향상)
        hidden_states = outputs.hidden_states
        last_four = torch.stack(hidden_states[-4:])
        avg_hidden = torch.mean(last_four, dim=0)
        cls_output = avg_hidden[:, 0]

        cls_output = self.dropout(cls_output)
        logits = self.classifier(cls_output)

        loss = None
        if labels is not None:
            loss = self.loss_fn(logits, labels)

        return {'loss': loss, 'logits': logits}

# 4. 학습 설정
# KLUE-BERT 토크나이저 초기화
tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')

# 데이터 분할: 학습/검증 (8:2)
train_df, val_df = train_test_split(
    pairwise_df, 
    test_size=0.2, 
    stratify=pairwise_df['label'], 
    random_state=42
)

# dataset 생성
train_dataset = SentencePairDataset(train_df, tokenizer, max_length=MAX_TOKEN_LENGTH)
val_dataset = SentencePairDataset(val_df, tokenizer, max_length=MAX_TOKEN_LENGTH)

print(f"Train 데이터: {len(train_dataset)} 샘플")
print(f"Validation 데이터: {len(val_dataset)} 샘플")
print(f"Train 클래스 분포: {train_df['label'].value_counts().to_dict()}")
print(f"Val 클래스 분포: {val_df['label'].value_counts().to_dict()}")

# GPU 사용 여부 확인
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"사용 디바이스: {device}")

# 클래스 가중치를 디바이스로 이동
class_weights = class_weights.to(device)

# KLUE-BERT 모델 인스턴스 생성
model = SentencePairModel("klue/bert-base", class_weights=class_weights).to(device)

# 샘플 데이터로 테스트
sample = train_dataset[0]
print("\n=== 샘플 데이터 확인 ===")
print(f"Input IDs shape: {sample['input_ids'].shape}")
print(f"Attention Mask shape: {sample['attention_mask'].shape}")
print(f"Label: {sample['labels']}")

# 개선된 평가 지표 함수
def compute_metrics(pred):
    logits, labels = pred
    preds = logits.argmax(axis=1)
    probs = torch.softmax(torch.tensor(logits), dim=1)
    
    # 기본 지표
    accuracy = accuracy_score(labels, preds)
    f1 = f1_score(labels, preds, zero_division=0)
    precision = precision_score(labels, preds, zero_division=0)
    recall = recall_score(labels, preds, zero_division=0)
    
    # ROC-AUC (positive class 확률 사용)
    try:
        auc = roc_auc_score(labels, probs[:, 1])
    except:
        auc = 0.0
    
    return {
        'accuracy': accuracy,
        'f1': f1,
        'precision': precision,
        'recall': recall,
        'auc': auc
    }

# 학습 인자 설정 (개선된 버전)
training_args = TrainingArguments(
    output_dir='./klue_bert_results',
    num_train_epochs=5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=64,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='./klue_bert_logs',
    logging_steps=100,
    save_strategy='epoch',
    eval_strategy='epoch',
    seed=42,
    load_best_model_at_end=True,
    metric_for_best_model='f1',  # F1 스코어로 변경
    greater_is_better=True,
    report_to='none'
)

# 트레이너 초기화
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
)

# 학습 실행
print("KLUE-BERT 모델 학습 시작...")
trainer.train()

# 최종 평가
eval_results = trainer.evaluate()
print("=== 최종 Validation 결과 ===")
for key, value in eval_results.items():
    if key.startswith('eval_'):
        print(f"{key}: {value:.4f}")

# 5. 결과 분석 및 시각화
# 예측 결과 분석
predictions = trainer.predict(val_dataset)
preds = predictions.predictions.argmax(axis=1)
labels = predictions.label_ids
probs = torch.softmax(torch.tensor(predictions.predictions), dim=1)

# Confusion Matrix
cm = confusion_matrix(labels, preds)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

# Classification Report
print("\n=== Classification Report ===")
print(classification_report(labels, preds))

# ROC Curve
fpr, tpr, _ = roc_curve(labels, probs[:, 1])
auc_score = roc_auc_score(labels, probs[:, 1])

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc_score:.3f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# 클래스별 예측 분포 분석
plt.figure(figsize=(12, 4))

plt.subplot(1, 2, 1)
plt.hist(probs[:, 0], bins=50, alpha=0.7, label='Class 0 (Wrong Order)', color='red')
plt.hist(probs[:, 1], bins=50, alpha=0.7, label='Class 1 (Correct Order)', color='blue')
plt.xlabel('Prediction Probability')
plt.ylabel('Frequency')
plt.title('Prediction Probability Distribution')
plt.legend()

plt.subplot(1, 2, 2)
class_0_probs = probs[labels == 0, 1]
class_1_probs = probs[labels == 1, 1]
plt.hist(class_0_probs, bins=30, alpha=0.7, label='True Class 0', color='red')
plt.hist(class_1_probs, bins=30, alpha=0.7, label='True Class 1', color='blue')
plt.xlabel('Class 1 Probability')
plt.ylabel('Frequency')
plt.title('Probability Distribution by True Class')
plt.legend()

plt.tight_layout()
plt.show()

# 6. 추론 및 예측
# 개선된 예측 함수
def predict_order(sent1, sent2, model, tokenizer, device='cpu'):
    model.eval()
    inputs = tokenizer(
        sent1,
        sent2,
        return_tensors='pt',
        padding=True,
        truncation=True,
        max_length=MAX_TOKEN_LENGTH
    )
    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.softmax(outputs['logits'], dim=1)

    return predictions, predictions.argmax().item()

# 페어와이즈 점수 계산 함수
def pair_score(s1, s2):
    probs, _ = predict_order(s1, s2, model, tokenizer, device)
    return probs[0][1].item()  # label=1 확률

# 효율적인 순열 탐색 (Greedy 알고리즘)
def find_best_order_greedy(sentences):
    """Greedy 알고리즘으로 최적 순서 찾기"""
    n = len(sentences)
    if n <= 1:
        return list(range(n))
    
    # 첫 번째 문장 선택 (가장 높은 점수를 받는 문장)
    best_first = 0
    best_score = -1
    
    for i in range(n):
        total_score = 0
        for j in range(n):
            if i != j:
                total_score += pair_score(sentences[i], sentences[j])
        if total_score > best_score:
            best_score = total_score
            best_first = i
    
    # 나머지 문장들을 순차적으로 배치
    remaining = list(range(n))
    remaining.remove(best_first)
    
    result = [best_first]
    current = best_first
    
    while remaining:
        best_next = remaining[0]
        best_score = pair_score(sentences[current], sentences[remaining[0]])
        
        for next_idx in remaining[1:]:
            score = pair_score(sentences[current], sentences[next_idx])
            if score > best_score:
                best_score = score
                best_next = next_idx
        
        result.append(best_next)
        remaining.remove(best_next)
        current = best_next
    
    return result

# 테스트 데이터 예측
pred_orders = []
pred_scores = []

print("테스트 데이터 예측 시작...")
for idx, (_, row) in enumerate(tqdm(test.iterrows(), total=len(test), desc="문장 순서 예측")):
    sents = [row[f'sentence_{i}'] for i in range(4)]
    
    # Greedy 알고리즘 사용
    best_perm = find_best_order_greedy(sents)
    
    # 점수 계산
    score = sum(pair_score(sents[best_perm[i]], sents[best_perm[i+1]]) for i in range(3))
    
    pred_orders.append(best_perm)
    pred_scores.append(score)
    
    # 진행상황 출력
    if (idx + 1) % 100 == 0:
        print(f"[{idx+1}/{len(test)}] 완료, 현재 평균 점수: {np.mean(pred_scores):.4f}")

# Submission 파일 생성
for idx, perm in enumerate(pred_orders):
    for i, p in enumerate(perm):
        submission.loc[idx, f'answer_{i}'] = p

submission.to_csv('klue_bert_results/submission.csv', index=False)
print("✅ submission.csv 파일이 생성되었습니다.")
print(f"예측된 순서의 평균 점수: {np.mean(pred_scores):.4f}")
print(f"예측된 순서 샘플: {pred_orders[:5]}")

# 7. 추가 분석 및 인사이트
# 예측 결과 분석
print("=== 예측 결과 분석 ===")
print(f"평균 예측 점수: {np.mean(pred_scores):.4f}")
print(f"최고 예측 점수: {np.max(pred_scores):.4f}")
print(f"최저 예측 점수: {np.min(pred_scores):.4f}")
print(f"예측 점수 표준편차: {np.std(pred_scores):.4f}")

# 점수 분포 시각화
plt.figure(figsize=(10, 6))
plt.hist(pred_scores, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
plt.axvline(np.mean(pred_scores), color='red', linestyle='--', label=f'평균: {np.mean(pred_scores):.4f}')
plt.xlabel('예측 점수')
plt.ylabel('빈도')
plt.title('테스트 데이터 예측 점수 분포')
plt.legend()
plt.show()

# 모델 성능 요약
print("=== KLUE-BERT 모델 성능 요약 ===")
print(f"Validation Accuracy: {eval_results['eval_accuracy']:.4f}")
print(f"Validation F1 Score: {eval_results['eval_f1']:.4f}")
print(f"Validation Precision: {eval_results['eval_precision']:.4f}")
print(f"Validation Recall: {eval_results['eval_recall']:.4f}")
print(f"Validation AUC: {eval_results['eval_auc']:.4f}")
print(f"테스트 예측 평균 점수: {np.mean(pred_scores):.4f}")

# 예측 순서의 다양성 분석
unique_orders = set()
for pred in pred_orders:
    unique_orders.add(tuple(pred))

print(f"\n고유한 예측 순서 수: {len(unique_orders)}")
print(f"예측 다양성 비율: {len(unique_orders)/len(pred_orders)*100:.2f}%")

# 파일 다운로드
from google.colab import files
files.download('klue_bert_results/submission.csv')

print("✅ submission.csv 파일이 다운로드되었습니다.")
print("\n=== 최종 결과 ===")
print(f"모델: KLUE-BERT")
print(f"방식: Pairwise")
print(f"Validation F1: {eval_results['eval_f1']:.4f}")
print(f"테스트 예측 완료: {len(pred_orders)} 샘플")
